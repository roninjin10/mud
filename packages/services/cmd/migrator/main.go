package main

import (
	"flag"
	"fmt"
	"io/ioutil"
	"math/big"
	"strings"

	"latticexyz/mud/packages/services/pkg/logger"
	"latticexyz/mud/packages/services/pkg/mode"
	pb "latticexyz/mud/packages/services/protobuf/go/ecs-snapshot"

	"github.com/ethereum/go-ethereum/common/hexutil"

	"github.com/jmoiron/sqlx"
	_ "github.com/lib/pq"
	"github.com/umbracle/ethgo"
	"github.com/umbracle/ethgo/abi"
	"go.uber.org/zap"
	"google.golang.org/protobuf/proto"
)

// Type definitions. These can be autogenerated, but for the purposes of illlustration
// we manually create a type for every struct that exists contract-side for MUD V1 data
// that we are migrating.
//
// Note that the below structs are for OPCraft V1 components. Also note that this is needed
// for structs only, as singular data types can be parsed directly.

// A type identifier identifies a struct. Also can autogen.
const (
	SolidityTypeIdentifierClaim      string = "tuple(uint32 stake, uint256 claimer)"
	SolidityTypeIdentifierOccurrence string = "tuple(address contr, bytes4 func)"
	SolidityTypeIdentifierPosition   string = "tuple(int32 x, int32 y, int32 z)"
)

type Claim struct {
	Stake   uint32
	Claimer *big.Int
}

type Occurrence struct {
	Contr ethgo.Address
	Func  [4]byte
}

type Position struct {
	X int32
	Y int32
	Z int32
}

var (
	// General flags.
	dsn = flag.String("dsn", "postgresql://localhost:5432/mode?sslmode=disable", "Connection string to Postgres")

	// Locations for data that migrator needs to work with.
	dataPath       = flag.String("data-path", "./snapshots/OPCRAFT_STATE/OPCRAFT_STATE_SerializedECSState-latest-0x3031a86EFA3A9c0B41EA089F2021C6490591fB8c", "Path to binary in V1 format to migrate to Postgres")
	dataSchemaPath = flag.String("schema-path", "./OPCraftDataSchema.json", "Path to schema JSON file that is used to deconstruct the binary file")
)

func connectToDatabase(dsn string, schema string) (*sqlx.DB, error) {
	db, err := sqlx.Connect("postgres", dsn)
	if err != nil {
		return nil, err
	}

	var dbName string
	err = db.Get(&dbName, "SELECT current_database()")
	if err != nil {
		return nil, err
	}
	logger.GetLogger().Info("connected to db", zap.String("name", dbName))

	_, err = db.Exec(schema)
	if err != nil {
		logger.GetLogger().Error("error executing schema", zap.String("schema", schema))
		return nil, err
	}

	return db, nil
}

func buildValueFields(valueSchema map[string]mode.DataSchemaTypePair) string {
	if len(valueSchema) == 0 {
		return ""
	}
	valueFields := ""
	for field := range valueSchema {
		fieldTypePair := valueSchema[field]
		valueFields = valueFields + `, ` + field + ` ` + fieldTypePair.PostgresType
	}
	return valueFields
}

func buildCreateTable(tableName string, valueSchema map[string]mode.DataSchemaTypePair) string {
	valueFields := buildValueFields(valueSchema)

	return `CREATE TABLE IF NOT EXISTS ` + tableName + ` (
		entityId          text PRIMARY KEY
	` + valueFields + `
	);`
}

func buildIndexOnTable(tableName string, valueSchema map[string]mode.DataSchemaTypePair) string {
	var indexStr strings.Builder

	for field := range valueSchema {
		indexStr.WriteString(`CREATE INDEX IF NOT EXISTS ` + tableName + `_` + field + `_idx ON ` + tableName + `("` + field + `");`)
	}
	return indexStr.String()
}

func buildDatabaseSchema(state *pb.ECSStateSnapshot, dataSchema *mode.DataSchema) (string, error) {
	var schema strings.Builder

	for componentIdIdx := range state.StateComponents {
		// Create tables from components. Lookup the more readable name of the component from
		// the parsed schema object.
		componentId := state.StateComponents[componentIdIdx]
		readableComponentName := dataSchema.ComponentMapping[componentId]

		// Lookup the component value schema (in order to store in structured way in DB).
		componentValueSchema := dataSchema.ComponentValueSchema[componentId]

		if readableComponentName != "" {
			// Create table.
			schema.WriteString(buildCreateTable(readableComponentName, componentValueSchema))
			// Auto-create any indexes (based on the table).
			schema.WriteString(buildIndexOnTable(readableComponentName, componentValueSchema))
		}
	}

	return schema.String(), nil
}

func loadDefaultSolidityType(solidityTypeIdentifier string, decoded interface{}, entityId string, componentTableName string, db *sqlx.DB) error {
	insertStmt, err := db.Prepare("INSERT INTO " + componentTableName + " (entityid, value) VALUES ($1, $2)")
	if err != nil {
		return err
	}
	defer insertStmt.Close()

	// Execute the insert statement.
	if solidityTypeIdentifier == "uint32" {
		value := decoded.(uint32)
		_, err = insertStmt.Exec(entityId, value)
	} else if solidityTypeIdentifier == "uint256" {
		value := decoded.(*big.Int)
		_, err = insertStmt.Exec(entityId, hexutil.EncodeBig(value))
	} else if solidityTypeIdentifier == "text" {
		value := decoded.(string)
		_, err = insertStmt.Exec(entityId, value)
	} else if solidityTypeIdentifier == "bool" {
		value := decoded.(bool)
		_, err = insertStmt.Exec(entityId, value)
	}

	return err
}

func loadIntoDatabase(stateSnapshot *pb.ECSStateSnapshot, dataSchema *mode.DataSchema, db *sqlx.DB) error {
	logger.GetLogger().Info("preparing to insert state", zap.Int("entries", len(stateSnapshot.State)))
	for counter, stateSlice := range stateSnapshot.State {
		// First read the indexes from the snapshot, then lookup the actual
		// component / entity id values from the array.
		componentIdIdx := stateSlice.ComponentIdIdx
		entityIdIdx := stateSlice.EntityIdIdx

		componentId := stateSnapshot.StateComponents[componentIdIdx]
		entityId := stateSnapshot.StateEntities[entityIdIdx]

		// Extract information from the data schema.
		componentTableName := dataSchema.ComponentMapping[componentId]
		solidityTypeIdentifier := dataSchema.ComponentSolidityTypeMapping[componentId]

		// Skip if there is no mapping to lookup, i.e. no type for component.
		if solidityTypeIdentifier == "" {
			continue
		}

		// A solidity type is used to decode the raw value.
		solidityType := abi.MustNewType(solidityTypeIdentifier)
		rawValue := stateSlice.Value

		// Insert into DB.
		// TODO: can make this more generic but for now each "parsing" condition
		// needs to be implemented per on-chain type of value that is stored.
		switch solidityTypeIdentifier {
		case SolidityTypeIdentifierClaim:
			// Decode into a struct.
			var value Claim
			if err := solidityType.DecodeStruct(rawValue, &value); err != nil {
				panic(err)
			}

			insertStmt, err := db.Prepare("INSERT INTO " + componentTableName + " (entityid, stake, claimer) VALUES ($1, $2, $3)")
			if err != nil {
				return err
			}
			defer insertStmt.Close()

			// Execute the insert statement.
			_, err = insertStmt.Exec(entityId, value.Stake, hexutil.EncodeBig(value.Claimer))
			if err != nil {
				return err
			}

		case SolidityTypeIdentifierPosition:
			var value Position
			if err := solidityType.DecodeStruct(rawValue, &value); err != nil {
				panic(err)
			}

			insertStmt, err := db.Prepare("INSERT INTO " + componentTableName + " (entityid, x, y, z) VALUES ($1, $2, $3, $4)")
			if err != nil {
				return err
			}
			defer insertStmt.Close()

			// Execute the insert statement.
			_, err = insertStmt.Exec(entityId, value.X, value.Y, value.Z)
			if err != nil {
				return err
			}

		case SolidityTypeIdentifierOccurrence:
			var value Occurrence
			if err := solidityType.DecodeStruct(rawValue, &value); err != nil {
				panic(err)
			}

			insertStmt, err := db.Prepare("INSERT INTO " + componentTableName + " (entityid, contr, func) VALUES ($1, $2, $3)")
			if err != nil {
				return err
			}
			defer insertStmt.Close()

			// Execute the insert statement.
			_, err = insertStmt.Exec(entityId, value.Contr.String(), hexutil.Encode(value.Func[:]))
			if err != nil {
				return err
			}

		default:
			// Decode into simple type by default.
			decoded, err := solidityType.Decode(rawValue)
			if err != nil {
				return err
			}

			err = loadDefaultSolidityType(solidityTypeIdentifier, decoded, entityId, componentTableName, db)
			if err != nil {
				return err
			}
		}

		if counter%100000 == 0 {
			logger.GetLogger().Info(fmt.Sprintf("%d/%d inserted", counter, len(stateSnapshot.State)))
		}
	}
	return nil
}

func main() {
	// Parse command line flags.
	flag.Parse()

	// Setup logging.
	logger.InitLogger()
	logger := logger.GetLogger()
	defer logger.Sync()

	dataSchema := mode.NewDataSchemaFromJSON(*dataSchemaPath)

	encoding, err := ioutil.ReadFile(*dataPath)
	if err != nil {
		logger.Fatal("failed to read encoded state", zap.String("dataPath", *dataPath), zap.Error(err))
	}

	stateSnapshot := &pb.ECSStateSnapshot{}
	if err := proto.Unmarshal(encoding, stateSnapshot); err != nil {
		logger.Error("failed to decode ECSState", zap.Error(err))
	}
	logger.Info("decoded MUD V1 snapshot", zap.Int("ecs events length", len(stateSnapshot.State)))

	schema, err := buildDatabaseSchema(stateSnapshot, dataSchema)
	if err != nil {
		logger.Fatal("error building db schema", zap.Error(err))
	}
	logger.Info("built DB schema from snapshot", zap.String("schema", schema))

	// Connect to the database and execute the schema.
	db, err := connectToDatabase(*dsn, schema)
	if err != nil {
		logger.Fatal("error connecting to db", zap.Error(err))
	}

	err = loadIntoDatabase(stateSnapshot, dataSchema, db)
	if err != nil {
		logger.Fatal("error loading data into db", zap.Error(err))
	}

	logger.Info("migration complete")
}
